import streamlit as st
import os
import fitz  # PyMuPDF
from PIL import Image, ImageEnhance, ImageFilter
import re
import json
from googleapiclient.discovery import build
from oauth2client.service_account import ServiceAccountCredentials
import io
from googleapiclient.http import MediaIoBaseDownload
import pytesseract

import platform
import pytesseract

# âœ… OSì— ë”°ë¼ Tesseract ê²½ë¡œ ìë™ ì„¤ì •
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"  # Streamlit Cloud/Linux ê¸°ë³¸ ê²½ë¡œ


def load_google_service_account_key():
    return st.secrets["gcp"]

# âœ… Google Drive ì—°ê²° í•¨ìˆ˜
@st.cache_resource(ttl=3000, show_spinner=False)
def get_drive_service():
    scope = ['https://www.googleapis.com/auth/drive']
    key_dict = load_google_service_account_key()
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    return build('drive', 'v3', credentials=creds)

# âœ… Google Driveì—ì„œ íŒë‹¨ë³„_ì„¤ëª….json ë¡œë“œ
@st.cache_data(ttl=3000, show_spinner=False)
def load_explain_data_from_drive():
    service = get_drive_service()

    # Google Drive ê³µìœ  URLì—ì„œ íŒŒì¼ ID ì¶”ì¶œ
    file_id = "1n17KiyaQ5cp_xFjgzFtmrE2Hvoqh5aXC"

    request = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return json.load(fh)

# âœ… ê¸°ì¡´ ë¡œì»¬ íŒŒì¼ ëŒ€ì‹  Driveì—ì„œ ë¡œë“œ
explain_data = load_explain_data_from_drive()

# Tesseract ê²½ë¡œ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# ì´ìƒì  ë²”ìœ„
ideal_ranges = {
    "ì§€ì§€í‘œí˜„": (65, 85),
    "í•©ë¦¬ì  ì„¤ëª…": (65, 85),
    "ì„±ì·¨ì••ë ¥": (50, 70),
    "ê°„ì„­": (40, 60),
    "ì²˜ë²Œ": (30, 50),
    "ê°ë…": (30, 50),
    "ê³¼ì‰ê¸°ëŒ€": (20, 40),
    "ë¹„ì¼ê´€ì„±": (10, 30)
}
factors_order = list(ideal_ranges.keys())

def extract_pat_graph_by_render(pdf_bytes, page_num=2):
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page = doc[page_num]
    pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))
    # ê·¸ë˜í”„ ì˜ë¼ë‚´ê¸°
    graph_bbox = (82, 130, 550, 470)
    crop_pix = page.get_pixmap(matrix=fitz.Matrix(3, 3), clip=graph_bbox)
    return crop_pix.tobytes("png")

def preprocess_image(image_path):
    img = Image.open(image_path).convert("L")
    img = img.filter(ImageFilter.MedianFilter())
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(2)
    img = img.point(lambda x: 0 if x < 140 else 255, '1')
    return img

def evaluate_results(percentiles):
    results = []
    for i, value in enumerate(percentiles):
        low, high = ideal_ranges[factors_order[i]]
        if value < low:
            results.append("ë¯¸í¡í•¨")
        elif value > high:
            results.append("ì§€ë‚˜ì¹¨")
        else:
            results.append("ì´ìƒì ì„")
    return results

def ocr_pat_graph(image_path):
    img = preprocess_image(image_path)
    text = pytesseract.image_to_string(img, lang="kor+eng")
    seq_match = re.search(r"(\d+\s+){7}\d+", text)
    numbers = []
    if seq_match:
        numbers = [int(n) for n in re.findall(r"\d+", seq_match.group()) if 10 <= int(n) <= 100]
    evaluated = evaluate_results(numbers) if len(numbers) == 8 else []
    return {"ë°±ë¶„ìœ„": numbers, "ê²°ê³¼": evaluated}

# íŒë‹¨ë³„ ì„¤ëª… ë¡œë“œ
explain_data = load_explain_data_from_drive()

def explain_results(evaluated):
    ideal_titles, ideal_texts, non_titles, non_texts = [], [], [], []
    for key, value in zip(factors_order, evaluated):
        if value == "ì´ìƒì ì„":
            ideal_titles.append(key)
            ideal_texts.append(explain_data[key]["ì´ìƒì ì„"])
        elif value == "ë¯¸í¡í•¨":
            non_titles.append(key)
            non_texts.append(explain_data[key]["ë¯¸í¡í•¨"])
        elif value == "ì§€ë‚˜ì¹¨":
            non_titles.append(key)
            non_texts.append(explain_data[key]["ì§€ë‚˜ì¹¨"])
    return ideal_titles, ideal_texts, non_titles, non_texts

# ---------------------------
# âœ… Streamlit Web UI
# ---------------------------
# --- ê¸°ì¡´ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    st.title("ğŸ“„ PAT PDF ë¶„ì„ê¸°")

    uploaded_pdf = st.file_uploader("PAT PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    if uploaded_pdf:
        # ê·¸ë˜í”„ ì´ë¯¸ì§€ ì¶”ì¶œ
        graph_img_bytes = extract_pat_graph_by_render(uploaded_pdf.read())
        graph_img_path = "temp_graph.png"
        with open(graph_img_path, "wb") as f:
            f.write(graph_img_bytes)

        st.image(graph_img_path, caption="ì¶”ì¶œëœ ê·¸ë˜í”„", use_column_width=True)

        # OCR + ê²°ê³¼
        data = ocr_pat_graph(graph_img_path)
        st.subheader("âœ… OCR ê²°ê³¼")
        st.write(f"**ë°±ë¶„ìœ„:** {data['ë°±ë¶„ìœ„']}")
        st.write(f"**ê²°ê³¼:** {data['ê²°ê³¼']}")

        # ì„¤ëª… ì¶œë ¥
        if data["ê²°ê³¼"]:
            ideal_titles, ideal_texts, non_titles, non_texts = explain_results(data["ê²°ê³¼"])

            st.subheader(f"[ì´ìƒì ì„] ì˜ì—­ ì„¤ëª… - {', '.join(ideal_titles)}")
            for txt in ideal_texts:
                st.write(txt)

            st.subheader(f"[ë¯¸í¡í•¨ ë˜ëŠ” ì§€ë‚˜ì¹¨] ì˜ì—­ ì„¤ëª… - {', '.join(non_titles)}")
            for txt in non_texts:
                st.write(txt)
