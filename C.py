import streamlit as st
import json
import re
import pdfplumber
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload  # âœ… ì¶”ê°€
from oauth2client.service_account import ServiceAccountCredentials
import io

def load_google_service_account_key():
    return st.secrets["gcp"]

@st.cache_resource(ttl=3000, show_spinner=False)
def get_drive_service():
    scope = ['https://www.googleapis.com/auth/drive']
    key_dict = load_google_service_account_key()
    creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
    return build('drive', 'v3', credentials=creds)

@st.cache_data(ttl=3000, show_spinner=False)
def load_temperament_dict_from_drive():
    service = get_drive_service()

    file_id = "1TZzYppfIZB7GowdBiTf5dDYEV6_7AXbj"  # âœ… Google Drive íŒŒì¼ ID

    request = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return json.load(fh)


# ---------------------------
# 1) TCI ë°±ë¶„ìœ„ H/M/L ì¶”ì¶œ
# ---------------------------
def extract_tci_percentiles(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        page = pdf.pages[0]
        text = page.extract_text()

    lines = text.split("\n")
    tci_scales = [
        "ìê·¹ì¶”êµ¬", "ìœ„í—˜íšŒí”¼", "ì‚¬íšŒì  ë¯¼ê°ì„±", "ì¸ë‚´ë ¥",
        "ììœ¨ì„±", "ì—°ëŒ€ê°", "ìê¸°ì´ˆì›”", "ììœ¨ì„±+ì—°ëŒ€ê°"
    ]
    tci_codes = ["NS", "HA", "RD", "PS", "SD", "CO", "ST", "SC"]

    percentiles = {}
    seen = set()
    for line in lines:
        for scale, code in zip(tci_scales, tci_codes):
            if (scale in line or code in line) and scale not in seen:
                nums = re.findall(r"\d+", line)
                if len(nums) >= 3:
                    p = int(nums[2])
                    level = "H" if p > 65 else "M" if p >= 35 else "L"
                    percentiles[scale] = {"percentile": p, "level": level}
                    seen.add(scale)
    return percentiles

# ---------------------------
# 2) TCI í•˜ìœ„ì²™ë„ M(SD) ì¶”ì¶œ
# ---------------------------
def extract_tci_m_sd(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        page = pdf.pages[1]
        text = page.extract_text()

    lines = text.split("\n")
    m_sd_result = {}
    pattern = re.compile(r"([A-Z]{2}\d)\s+\d+\s+([\d.]+)\s*\(([\d.]+)\)")
    for line in lines:
        match = pattern.search(line)
        if match:
            subscale = match.group(1)
            m_sd_result[subscale] = {"M": float(match.group(2)), "SD": float(match.group(3))}
    return m_sd_result

# ---------------------------
# 3) JSON ë¡œë“œ
# ---------------------------
def load_temperament_dict(json_path):
    with open(json_path, "r", encoding="utf-8") as jf:
        return json.load(jf)

# ---------------------------
# 4) ì‚¬íšŒì  ë¯¼ê°ì„± ë³´ì • ë¡œì§
# ---------------------------
def adjust_social_sensitivity(hml: dict, m_sd: dict) -> str:
    rd_level = hml["ì‚¬íšŒì  ë¯¼ê°ì„±"]
    if rd_level == "H":
        rd3 = m_sd.get("RD3", {}).get("M", 0)
        rd4 = m_sd.get("RD4", {}).get("M", 0)
        if rd3 >= 11.6 + 3.3 and rd4 <= 9.4 - 2.6:
            return "H(ì¹œë°€+ë…ë¦½)"
        elif rd4 >= 9.4 + 2.6 and rd3 <= 11.6 - 3.3:
            return "H(ê±°ë¦¬ë‘ê¸°+ì˜ì¡´)"
        else:
            return "H(ì¹œë°€+ì˜ì¡´)"
    elif rd_level == "L":
        rd1 = m_sd.get("RD1", {}).get("M", 0)
        if rd1 >= 11.1 - 2.9:
            return "L(ë†’ì€/ì ì ˆí•œ ì •ì„œì  ê°ìˆ˜ì„±)"
        else:
            return "L(typical)"
    return rd_level

# ---------------------------
# 5) ë§¤ì¹­ í‚¤ ìƒì„±
# ---------------------------
def build_matching_Temperament_keys(hml: dict, m_sd: dict) -> dict:
    social_key = adjust_social_sensitivity(hml, m_sd)
    return {
        "ê¸°ì§ˆ1": f"ìê·¹ì¶”êµ¬{hml['ìê·¹ì¶”êµ¬']} ìœ„í—˜íšŒí”¼{hml['ìœ„í—˜íšŒí”¼']} ì¸ë‚´ë ¥{hml['ì¸ë‚´ë ¥']}",
        "ê¸°ì§ˆ2": f"ìê·¹ì¶”êµ¬{hml['ìê·¹ì¶”êµ¬']} ìœ„í—˜íšŒí”¼{hml['ìœ„í—˜íšŒí”¼']} ì‚¬íšŒì ë¯¼ê°ì„±{social_key}",
        "ì„±ê²©": f"ììœ¨ì„±{hml['ììœ¨ì„±']} ì—°ëŒ€ê°{hml['ì—°ëŒ€ê°']}"
    }

def build_matching_Summary_keys(hml: dict, m_sd: dict) -> dict:
    social_key = adjust_social_sensitivity(hml, m_sd)
    return {
        "ìš”ì•½ë°ì œì–¸1": f"ìê·¹ì¶”êµ¬{hml['ìê·¹ì¶”êµ¬']} ìœ„í—˜íšŒí”¼{hml['ìœ„í—˜íšŒí”¼']} ì¸ë‚´ë ¥{hml['ì¸ë‚´ë ¥']}",
        "ìš”ì•½ë°ì œì–¸2": f"ìê·¹ì¶”êµ¬{hml['ìê·¹ì¶”êµ¬']} ìœ„í—˜íšŒí”¼{hml['ìœ„í—˜íšŒí”¼']} ì‚¬íšŒì ë¯¼ê°ì„±{social_key}",
        "ìš”ì•½ë°ì œì–¸3": f"ììœ¨ì„±{hml['ììœ¨ì„±']} ì—°ëŒ€ê°{hml['ì—°ëŒ€ê°']}"
    }

# ---------------------------
# 6) JSON ìœ ì‚¬ í‚¤ íƒìƒ‰
# ---------------------------
def find_best_matching_key(search_key: str, data: dict) -> tuple:
    if search_key in data:
        return search_key, "âœ… ì™„ì „ ë§¤ì¹­"
    candidates = [key for key in data if search_key.replace(" ", "") in key.replace(" ", "")]
    if candidates:
        return candidates[0], "ğŸ”„ ìœ ì‚¬ ë§¤ì¹­"
    return "", "âŒ ë§¤ì¹­ ì‹¤íŒ¨"

# ---------------------------
# 7) Streamlit UI
# ---------------------------
def main():
    st.title("ğŸ“Š TCI ê²°ê³¼ ë¶„ì„ (ì›¹ë²„ì „)")
    pdf_file = st.file_uploader("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

    # âœ… JSON íŒŒì¼ì€ ê³ ì • ì‚¬ìš©
    data = load_temperament_dict_from_drive()

    if pdf_file:
        with open("temp.pdf", "wb") as f:
            f.write(pdf_file.read())

        percentiles = extract_tci_percentiles("temp.pdf")
        m_sd = extract_tci_m_sd("temp.pdf")

        hml_values = {
            "ìê·¹ì¶”êµ¬": percentiles.get("ìê·¹ì¶”êµ¬", {}).get("level", "M"),
            "ìœ„í—˜íšŒí”¼": percentiles.get("ìœ„í—˜íšŒí”¼", {}).get("level", "M"),
            "ì‚¬íšŒì  ë¯¼ê°ì„±": percentiles.get("ì‚¬íšŒì  ë¯¼ê°ì„±", {}).get("level", "M"),
            "ì¸ë‚´ë ¥": percentiles.get("ì¸ë‚´ë ¥", {}).get("level", "M"),
            "ììœ¨ì„±": percentiles.get("ììœ¨ì„±", {}).get("level", "M"),
            "ì—°ëŒ€ê°": percentiles.get("ì—°ëŒ€ê°", {}).get("level", "M"),
        }

        st.subheader("âœ… ì¶”ì¶œëœ H/M/L ê°’")
        st.json(hml_values)

        matching_keys = build_matching_Temperament_keys(hml_values, m_sd)
        st.subheader("ğŸ” ë§¤ì¹­ í‚¤")
        st.json(matching_keys)

        st.subheader("ğŸ“Œ ìµœì¢… ê²°ê³¼")
        for part, key in matching_keys.items():
            matched_key, status = find_best_matching_key(key, data.get(part, {}))
            st.markdown(f"### **[{part}]**")
            st.write(f"- **ì¶”ì¶œëœ í‚¤**: {key}")
            st.write(f"- **ë§¤ì¹­ëœ í‚¤**: {matched_key if matched_key else 'ì—†ìŒ'}")
            st.write(f"- **ë§¤ì¹­ ìƒíƒœ**: {status}")
            if matched_key:
                st.success(data[part][matched_key])
            else:
                st.error("âŒ í•´ë‹¹ í‚¤ì— ëŒ€í•œ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")

        matching_keys = build_matching_Summary_keys(hml_values, m_sd)
        # âœ… ìš”ì•½ ë° ì œì–¸ ì¶”ê°€
        st.subheader("ğŸ“ ìš”ì•½ ë° ì œì–¸")
        for part, key in matching_keys.items():
            summary_dict = data.get(f"{part}", {})
            matched_key, status = find_best_matching_key(key, summary_dict)
            st.markdown(f"### **[{part}]**")
            st.write(f"- **ì¶”ì¶œëœ í‚¤**: {key}")
            st.write(f"- **ë§¤ì¹­ëœ í‚¤**: {matched_key if matched_key else 'ì—†ìŒ'}")
            st.write(f"- **ë§¤ì¹­ ìƒíƒœ**: {status}")
            if matched_key:
                st.info(summary_dict[matched_key])
            else:
                st.warning("âŒ ìš”ì•½ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
